{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, LocallyConnected2D, SeparableConv2D\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_data import import_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 parties rejetées par le goban, reste 5835 parties\n",
      "(37344, 9, 9, 4)\n",
      "(37344, 82)\n"
     ]
    }
   ],
   "source": [
    "X, y, _ = import_data()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 9, 9, 64)          2368      \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               2654720   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 82)                21074     \n",
      "=================================================================\n",
      "Total params: 2,883,858\n",
      "Trainable params: 2,883,602\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, input_shape=X[0].shape, padding =\"same\"))\n",
    "model.add(Conv2D(64, kernel_size=3, padding =\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=3, padding =\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(82, activation='sigmoid')) \n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mae', optimizer=opt)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch 1/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.1440 - val_loss: 0.1263\n",
      "Epoch 2/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.1262 - val_loss: 0.1164\n",
      "Epoch 3/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.1177 - val_loss: 0.1060\n",
      "Epoch 4/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.1074 - val_loss: 0.0886\n",
      "Epoch 5/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0961 - val_loss: 0.0775\n",
      "Epoch 6/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0902 - val_loss: 0.0714\n",
      "Epoch 7/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0866 - val_loss: 0.0678\n",
      "Epoch 8/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0839 - val_loss: 0.0637\n",
      "Epoch 9/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0821 - val_loss: 0.0613\n",
      "Epoch 10/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0805 - val_loss: 0.0612\n",
      "Epoch 11/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0794 - val_loss: 0.0571\n",
      "Epoch 12/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0784 - val_loss: 0.0568\n",
      "Epoch 13/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0775 - val_loss: 0.0560\n",
      "Epoch 14/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0765 - val_loss: 0.0546\n",
      "Epoch 15/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0760 - val_loss: 0.0544\n",
      "Epoch 16/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0753 - val_loss: 0.0538\n",
      "Epoch 17/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0749 - val_loss: 0.0526\n",
      "Epoch 18/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0744 - val_loss: 0.0528\n",
      "Epoch 19/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0739 - val_loss: 0.0506\n",
      "Epoch 20/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0734 - val_loss: 0.0502\n",
      "Epoch 21/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0729 - val_loss: 0.0504\n",
      "Epoch 22/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0725 - val_loss: 0.0489\n",
      "Epoch 23/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0721 - val_loss: 0.0488\n",
      "Epoch 24/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0718 - val_loss: 0.0492\n",
      "Epoch 25/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0714 - val_loss: 0.0472\n",
      "Epoch 26/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0710 - val_loss: 0.0476\n",
      "Epoch 27/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0709 - val_loss: 0.0479\n",
      "Epoch 28/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0705 - val_loss: 0.0471\n",
      "Epoch 29/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0703 - val_loss: 0.0469\n",
      "Epoch 30/30\n",
      "584/584 [==============================] - 4s 7ms/step - loss: 0.0700 - val_loss: 0.0456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4c1e030d30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparamètres\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "# training\n",
    "print(\"Training ...\")\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5617101e-03 1.2980124e-03 2.6070706e-03 1.9202434e-03 7.9850294e-03\n",
      " 9.7885007e-01 4.5369985e-04 4.9124775e-04 9.8596979e-04 7.7178515e-04\n",
      " 4.2480476e-02 2.9640496e-01 9.6044067e-04 1.9379430e-03 3.6592403e-04\n",
      " 7.0451538e-04 1.2362213e-03 5.3607812e-04 6.6860928e-03 9.7493705e-04\n",
      " 2.0564075e-03 9.5689367e-04 1.2840690e-03 5.4458168e-04 5.0091615e-04\n",
      " 2.2010817e-03 1.5298569e-03 3.9029205e-03 2.2861476e-03 1.0539457e-03\n",
      " 1.8680214e-04 3.1058947e-04 3.8917828e-04 1.4353293e-04 9.5648889e-04\n",
      " 1.1224241e-03 4.3201428e-03 4.4759154e-02 1.8706948e-03 6.1538506e-02\n",
      " 2.5476972e-04 2.0249073e-04 5.7889154e-04 9.2975469e-04 1.0931070e-03\n",
      " 9.8309213e-01 1.8251343e-01 1.8199503e-06 2.7075550e-05 3.1672241e-04\n",
      " 1.4558128e-03 2.3876356e-04 2.7031958e-04 1.0871741e-03 1.6826808e-02\n",
      " 2.6248729e-01 2.0463082e-01 3.4840909e-01 4.1328100e-04 3.0808622e-04\n",
      " 4.7657406e-04 1.0665577e-03 6.0201291e-04 4.2949259e-02 6.7785704e-01\n",
      " 9.5647031e-01 9.9844090e-04 7.4478769e-04 5.5926939e-04 6.9458445e-04\n",
      " 1.9363537e-03 1.7814881e-03 1.0147135e-01 1.4317532e-01 9.7505726e-02\n",
      " 1.5068293e-03 2.1841896e-03 2.5129985e-04 6.8420981e-04 2.8900709e-04\n",
      " 3.2448422e-03 1.2211843e-03]\n",
      "5.524935030708093\n"
     ]
    }
   ],
   "source": [
    "proba = model.predict(X_train)\n",
    "print(proba[5])\n",
    "print(sum(proba[5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
